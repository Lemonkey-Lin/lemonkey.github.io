<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Research</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">menu</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="courses.html">Courses</a></div>
<div class="menu-item"><a href="misc.html">Misc</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research</h1>
</div>
<h2>Manuscript</h2>
<p><a href="">Controlling the false discovery rate under dependency with the adaptively weighted bh procedure</a>, <b>Mengqi Lin</b>, and William Fithian. To appear.</p>
<h2>R package</h2>
<p><a href="dwbh">dwbh</a>, R package for dependence-adjusted weighted Benjamini-Hochberg and general step-up procedures, with adaptive weighting </p>
<h2>Projects</h2>
<p><a href="Mean">Field Asymptotics in Multiple Hypothesis Testing: Power analysis with LASSO statistics</a></p>
<h2>Research Statement</h2>
<p>I'm Will Fithian in Selective Inference and am doing research in this area. </p>
<ul>
<li><p>Some papers that I think are representative:</p>
</li>
</ul>
<p><a href="https://arxiv.org/abs/2007.10438">Conditional calibration for false discovery rate control under dependence</a></p>
<p><a href="https://arxiv.org/abs/0802.1406">Two simple sufficient conditions for fdr control</a></p>
<p><a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.00439.x">Strong control, conservative point estimation and simultaneous conservative consistency of false discovery rates: a unified approach</a></p>
<p><a href="https://arxiv.org/abs/1404.5609">Controlling the false discovery rate via knockoffs</a></p>
<p><a href="https://arxiv.org/abs/1609.06035">Adapt- an interactive procedure for multiple testing with side information</a></p>
<p><a href="https://arxiv.org/abs/1701.05179">Covariate-powered weighted multiple testing with false discovery rate control.</a></p>
<p><a href="https://arxiv.org/abs/1606.07926">Multiple testing with the structure-adaptive benjaminiâ€“ hochberg algorithm</a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3175141/">False discovery rate control with groups.</a></p>
<p><a href="https://arxiv.org/abs/1606.01969">Power of Ordered Hypothesis Test</a></p>
<p><a href="https://www.jstor.org/stable/20441304">False discovery control with p-value weighting</a></p>
<ul>
<li><p><a href="https://arxiv.org/abs/1712.06465">A Power and Prediction Analysis for Knockoffs with Lasso Statistics</a> </p>
</li>
</ul>
<p>Power analysis in multiple hypothesis is hard, and sometimes it's very specific to the testing you choose. Moreover, the analysis for sophisticated statistics like LASSO is even more difficult. Hoever, this paper leverages AMP theory (a powerful tool, I learned it from <a href="https://www.stat.berkeley.edu/~songmei/Teaching/STAT260_Spring2021/schedule.html">STAT 260</a>) to give an oracle trade off of FDR and TPP under some specific setting (asymptotic, pi_0 known), and compares the FDR and TPP of knockoff procedure, a predure widely used in practice for LASSO to prove the optimality of knockoff.</p>
</td>
</tr>
</table>
</body>
</html>
