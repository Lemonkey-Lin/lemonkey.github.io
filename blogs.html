<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Blogs</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">menu</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="courses.html">Courses</a></div>
<div class="menu-item"><a href="blogs.html">Blogs</a></div>
<div class="menu-item"><a href="misc.html">Misc</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Blogs</h1>
<div id="subtitle">This page is about some research that I'm interested in, as well as my thoughts on it. The topics are diverse, and some of them may be incorrect or naive.</div>
</div>
<h2>Roadmap of multiple hypothesis testing</h2>
<p>Testing millions of hypothesis simultaneously is commonly seen in various areas. To effectively report true discoveries, Yoav Benjamini and Yosef Hochberg  proposed a new criteria <b>FDR</b> in 1995 along with <a href="http://www.math.tau.ac.il/~ybenja/MyPapers/benjamini_hochberg1995.pdf">BH procedure</a> that controls FDR for independent and PRDS p-values. Multiple hypothesis testing has been a prominent issue ever since. </p>
<ul>
<li><p>Later on, <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.00439.x">John D. Storey, Jonathan E. Taylor, David Siegmund</a> proposed a <b>martingale view</b> of BH procedure and also proposed the <b>pi_0 estimation</b> problem. The martingale theory turns out to be a wonderful tool for constructing valid procedure under independency. Various procedures based on this theory includes <a href="https://arxiv.org/abs/1606.07926">SABHA</a>, <a href="https://arxiv.org/abs/1606.01969">Seq<tt></tt></a>, <a href="https://arxiv.org/abs/1609.06035">AdaPT</a></p>
</li>
</ul>
<ul>
<li><p>dependency problem: Scientists discovered the independent or PRDS assumption of <b>BH procedure</b> is too restricted and rarely appear in practice. 
<a href="https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-4/The-control-of-the-false-discovery-rate-in-multiple-testing/10.1214/aos/1013699998.full">Yoav Benjamini, Daniel Yekutieli</a> proposed <b>BY procedure</b>, which guarantees FDR control for arbitrary dependent p-values, yet with a big sacrifice of power. Later on, <a href="https://arxiv.org/abs/0802.1406">Gilles Blanchard , Etienne Roquain</a> generalizes this to <b>step-up procedure</b>. But still, these procedures are so conservative that greatly hinder their popularity for a long time. Until recently, <a href="https://arxiv.org/abs/2007.10438">Fithian and Lei</a> made a big breakthrough by using <b>conditional calibration technique</b>. Other procedure like <b>e-BH</b> by <a href="https://arxiv.org/pdf/2009.02824.pdf">Ruodu Wang, Aaditya Ramdas</a> also works for dependent statistics. But contrary to Ruodu's conjecture, I think e-BH procedure can even hardly beat BY procedure (See my discussion below)</p>
</li>
</ul>
<ul>
<li><p>Covariate assisted procedure: </p>
</li>
</ul>
<ul>
<li><p>Bayesian framwork: There's a very beautiful view of BH procedure &#8201;&mdash;&#8201; the bayesian two group model. 
Efron said <i>&ldquo;It is always a good sign when a statistical procedure enjoys both a frequentist and Bayesian support, and the BH algorithm passes the test.&rdquo;</i></p>
</li>
</ul>
<p><a href="https://www.jstor.org/stable/20441304">False discovery control with p-value weighting</a></p>
<p><a href="https://arxiv.org/abs/1701.05179">Covariate-powered weighted multiple testing with false discovery rate control.</a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3175141/">False discovery rate control with groups.</a></p>
<h2>Causal Inference</h2>
<p>One thing that makes me unease when I learn causal inference is its <b>non-testable assumptions</b>, which turns out to be the indispensable element for causal inference. </p>
<p>Indeed, Rubin created a valid language to help us answer causal questions with rigorous math, which I personally believe is also the only way to tackle causal problems. I mean, can you do inference outside the framework Rubin built? Honestly saying, I can't imagine reliable inference without the concept of <b>potential outcome</b>. </p>
<p>However, I found this framework to be troublesome when evaluating the performance of models. Because establishing <b>criteria of correctness</b> is hard, let alone calculating it, guaranteeing it. Take the easy propensity score model as an example, people assumed this model will fit an machine learning algorithm to calculate propensity scores and then plug in the estimator of average treatment effect. But, how can you guarantee your model has good property? <b>Does your algorithm guarantee some type I error?</b> I believe statistics is not black box, not automatic. But rather, one shall always keep mathematical guarantee in mind instead of doing things intuitively. </p>
<p>To make a breakthrough in these problems seems difficult, because the model itself is based on some <b>non testable assumptions</b>. Nevertheless, I appreciate the greatness and beauty Rubin built in causal inference. At least one thing I learned is that causal is really uneasy.</p>
<h2>Conformal Inference</h2>
<h2>Knockoff</h2>
<h2>A Power Analysis for knockoff</h2>
<p>Power analysis in multiple hypothesis is hard, analysis for sophisticated statistics like LASSO is even more difficult. 
In fact, inference based on LASSO statistics is not well addressed until <a href="https://arxiv.org/abs/1404.5609">Barber and Candes(2015)</a> made a breakthrough by proposing knockoff procedure. </p>
<p>But how well does it work? Power analysis for knockoff seems to rely on solely empirical results. </p>
<p>A powerful tool I learned in <a href="https://www.stat.berkeley.edu/~songmei/Teaching/STAT260_Spring2021/schedule.html">STAT 260 (Mean Field Asymptotics)</a>  provides an oracle picture of FDR-TPP trade-off under some specific settings (asymptotic, pi_0 known). With this tool in hand, we are able to compare the FDR and TPP in knockoff procedure and the &ldquo;oracle procedure&rdquo; to understand the performance of knockoff. </p>
<p>This is exactly what these papers are about.</p>
<ul>
<li><p><a href="https://arxiv.org/abs/1712.06465">A Power and Prediction Analysis for Knockoffs with Lasso Statistics</a> </p>
</li>
<li><p><a href="https://arxiv.org/abs/2007.15346">A Power Analysis for Knockoffs with the Lasso Coefficient-Difference Statistic</a></p>
</li>
</ul>
<h2>A note on e-values</h2>
<h2>Bayesian statistics</h2>
<p>I'm obsessed with viewing things in geometry prospective. One of the most beautiful theorem I learned in bayesian statistics is </p>
<p>/Every admissible estimator is a (possibly randomized) Bayes estimator for some prior.</p>
<p>where admissible estimator means/</p>
<h2>Robust statistics, resilience</h2>
<p>Check out <a href="Mengqi_Lin_Challenge_Problem_Sets.pdf">my solutions to the challgenging problems</a> for fun!</p>
</td>
</tr>
</table>
</body>
</html>
